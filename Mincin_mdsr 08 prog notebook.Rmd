---
title: "Mincin_mdsr 08 prog notebook"
author: "Kimberly Mincin"
date: "2/17/2019"
output: html_document
---

# Front matter

```{r echo=TRUE, message=FALSE}
# always clean up R environment
rm(list = ls())

# load all packages here
library(mosaic)
library(rpart)
library(partykit)
library(randomForest)
library(tibble)
library(class)

# user-defined functions here (if any)
knn_error_rate pg. 183

# load data


```


# Chapter Notes

## Section 8.1  


## Section 8.2


### Section 8.2.1


### Section 8.2.2

```{r}
# pg. 174

census <- read.csv(
  "http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data", header = FALSE)

names(census) <- c("age", "workclass", "fnlwgt", "education", "education.num", "marital.status", "occupation", "relationship", "race", "sex", "capital.gain", "capital.loss", "hours.per.week", "native.country", "income")

glimpse(census)
```

```{r}
# pg. 175

set.seed(364)

n <- nrow(census)

test_idx <- sample.int(n, size = round(0.2 * n))

train <- census[-test_idx, ]
nrow(train)

test <- census[test_idx, ]
nrow(test)
```

```{r}
# pg. 175

tally(~income, data = train, format = "percent")
```

```{r}
# pg. 176

rpart(income ~ capital.gain, data = train)
```

```{r}
# pg. 176

split <- 5095.5

train <-
  train %>%
  mutate(hi_cap_gains = capital.gain >= split)

train %>%
  ggplot(aes(x = capital.gain, y = income)) +
  geom_count(aes(color = hi_cap_gains), position = position_jitter(width = 0, height = .1),
             alpha = .5) +
  geom_vline(xintercept = split, color = "dodgerblue", lty = 2) +
  scale_x_log10(labels = scales::dollar)
```

```{r}
#  pg. 176

form <- as.formula("income ~ age + workclass + education + marital.status + occupation
                   + relationship + race + sex + capital.gain + capital.loss 
                   + hours.per.week")

mod_tree <- rpart(form, data = train)

mod_tree
```

```{r}
# pg. 177

plot(mod_tree)
text(mod_tree, use.n = TRUE, all = TRUE, cex = .7)
```

```{r}
# pg. 178

plot(as.party(mod_tree))
```

```{r}
# pg. 179

train <- 
  train %>%
  mutate(husband_or_wife = relationship %in% c(" Husband", " Wife"),
         college_degree = husband_or_wife & education %in% 
           c(" Bachelors", " Doctorate", " Masters", " Prof-school"),
         income_dtree = predict(mod_tree, type = "class"))

cg_splits <- data.frame(husband_or_wife = c(TRUE, FALSE), vals = c(5095.5, 7073.5))

train %>%
  ggplot(aes(x = capital.gain, y = income)) +
  geom_count(aes(color = income_dtree, shape = college_degree), 
             position = position_jitter(width = 0, height = .1), alpha = .5) +
  facet_wrap(~ husband_or_wife) +
  geom_vline(data = cg_splits, aes(xintercept = vals), color = "dodgerblue", lty = 2) +
  scale_x_log10()
```

```{r}
# pg. 180

printcp(mod_tree)
```

```{r}
# pg. 180

train <-
  train %>%
  mutate(income_dtree = predict(mod_tree, type = "class"))

confusion <- tally(income_dtree ~ income, data = train, format = "count")

confusion

sum(diag(confusion)) / nrow(train)
```


### 8.2.3

```{r}
# pg. 181

mod_tree2 <- rpart(form, data = train, control = rpart.control(cp = .002))
```


### 8.2.4

```{r}
# pg. 181

mod_forest <- randomForest(form, data = train, ntree = 201, mtry = 3)

mod_forest

sum(diag(mod_forest$confusion)) / nrow(train)
```

```{r}
# pg. 182

importance(mod_forest) %>%
  as.data.frame() %>%
  rownames_to_column() %>%
  arrange(desc(MeanDecreaseGini))
```

### 8.2.5

```{r}
# pg. 183

train_q <-
  train %>%
  select(age, education.num, capital.gain, capital.loss, hours.per.week)

income_knn <- knn(train_q, test = train_q, cl = train$income, k = 10)

confusion <- tally(income_knn ~ income, data = train, format = "count")
confusion

sum(diag(confusion)) / nrow(train)
```

```{r}
# pg. 183

knn_error_rate <- function(x, y, numNeighbors, z = x) {
  y_hat <- knn(train = x, test = z, cl = y, k = numNeighbors)
  return(sum(y_hat != y) / nrow(x))
}

ks <- c(1:15, 20, 30, 40, 50)

train_rates <- sapply(ks, FUN = knn_error_rate, x = train_q, y = train$income)

knn_error_rates <- data.frame(k = ks, train_rate = train_rates)

knn_error_rates %>%
  ggplot(aes(x = k, y = train_rate)) +
  geom_point() +
  geom_line() +
  ylab("Misclassification Rate")
```









